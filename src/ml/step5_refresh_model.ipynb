{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "# Estymacja pierwszego modelu i zapis w HDFS"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "# Prerequisites\n\n# !pip install pystan==2.19.1.1\n# !pip install fbprophet\n# !pip install plotly\n# !pip install --upgrade pretty-confusion-matrix --user"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "/opt/conda/anaconda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n  import pandas.util.testing as tm\n"}], "source": "from pyspark.sql import SparkSession\nfrom fbprophet import Prophet\n\nimport numpy as np\nimport pandas as pd\nfrom typing import List\nimport os\nfrom datetime import datetime\n\nfrom statsmodels.tsa.stattools import adfuller\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics\nimport seaborn as sns\nfrom pretty_confusion_matrix import pp_matrix\n\nfrom fbprophet.serialize import model_to_json, model_from_json"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "# Parameters\n\nLOCATION = \"Hamburg\"\nWEBSITE = \"Instagram\"\nTIME = \"day\"\n\ndate_col = 'ds'\ny_col = 'y'"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "# Auxiliary functions\n\n\ndef get_newest_train_fpath(root_dir=\"hdfs://cluster-bda2-m/user/root\"):\n    ls = !hdfs dfs -ls modeling/in\n    avail_files = [c for c in ls if f\"{str.lower(WEBSITE)}_{str.lower(LOCATION)}_{str.lower(TIME)}_train\" in c]\n\n    files_dict = {}\n\n    for f in avail_files:\n        date, time, name = f.split()[-3:]\n        creation_timestamp = datetime.strptime(\" \".join([date, time]), \"%Y-%m-%d %H:%M\")\n\n        files_dict[name] = creation_timestamp\n\n    return os.path.join(root_dir, max(files_dict, key=files_dict.get))\n\n\ndef load_parquet_from_HDFS(spark, fpath: List[str]):\n    df = spark.read.parquet(fpath)\n\n    return df\n\n\ndef estimate_prophet(df_train, date_col, y_col):\n    regressors = list(set(df_train.columns) - set([date_col, y_col]))\n    m = Prophet()\n\n    for c in regressors:\n        m.add_regressor(c)\n\n    m.fit(df_train.toPandas())\n    return m\n\n\ndef symmetric_mean_absolute_percentage_error(A, F):\n    with np.errstate(divide='ignore', invalid='ignore'):\n        tmp = 2 * np.abs(F-A) / (np.abs(A) + np.abs(F))\n    tmp[np.isnan(tmp)] = 0\n    return np.sum(tmp) / len(tmp) * 100\n\n\ndef get_version():\n    ls = !ls -l --time-style=long-iso models/\n    existing_versions = [c for c in ls if f\"{str.lower(WEBSITE)}_{str.lower(LOCATION)}_{str.lower(TIME)}_model\" in c]\n    return len(existing_versions)+1"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": "spark = SparkSession \\\n    .builder \\\n    .appName(\"Time series data analysis with Spark\") \\\n    .config(\"spark.redis.ssl\", \"true\") \\\n    .getOrCreate()"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "train_fpath = get_newest_train_fpath()"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "# load data from HDFS\ndf_train = load_parquet_from_HDFS(spark, train_fpath)"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "INFO:fbprophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n"}], "source": "# estimate regression model\nmodel = estimate_prophet(df_train, date_col, y_col)"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": "version = get_version()"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": "with open(f'models/{str.lower(WEBSITE)}_{str.lower(LOCATION)}_{str.lower(TIME)}_model{version}.json', 'w') as fout:\n    fout.write(model_to_json(model))  # Save model"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<fbprophet.forecaster.Prophet object at 0x7f9f4bf11590>\n"}], "source": "# Test\n\nwith open(f'models/{str.lower(WEBSITE)}_{str.lower(LOCATION)}_{str.lower(TIME)}_model{version}.json', 'r') as fin:\n    m = model_from_json(fin.read())  # Load model (test)\n    \nprint(m)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}